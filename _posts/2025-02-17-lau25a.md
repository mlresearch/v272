---
title: Quantile Multi-Armed Bandits with 1-bit Feedback
abstract: In this paper, we study a variant of best-arm identification involving elements
  of risk sensitivity and communication constraints. Specifically, the goal of the
  learner is to identify the arm with the highest quantile reward, while the communication
  from an agent (who observes rewards) and the learner (who chooses actions) is restricted
  to only one bit of feedback per arm pull. We propose an algorithm that utilizes
  noisy binary search as a subroutine, allowing the learner to estimate quantile rewards
  through 1-bit feedback. We derive an instance-dependent upper bound on the sample
  complexity of our algorithm and provide an algorithm-independent lower bound for
  specific instances, with the two matching to within logarithmic factors under mild
  conditions, or even to within constant factors in certain low error probability
  scaling regimes. The lower bound is applicable even in the absence of communication
  constraints, and thus we conclude that restricting to 1-bit feedback has a minimal
  impact on the scaling of the sample complexity.
openreview: u5xNVJlAse
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lau25a
month: 0
tex_title: Quantile Multi-Armed Bandits with 1-bit Feedback
firstpage: 664
lastpage: 699
page: 664-699
order: 664
cycles: false
bibtex_author: Lau, Ivan and Scarlett, Jonathan
author:
- given: Ivan
  family: Lau
- given: Jonathan
  family: Scarlett
date: 2025-02-17
address:
container-title: Proceedings of The 36th International Conference on Algorithmic Learning
  Theory
volume: '272'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 2
  - 17
pdf: https://raw.githubusercontent.com/mlresearch/v272/main/assets/lau25a/lau25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
