---
title: A Unified Theory of Supervised Online Learnability
abstract: We study the online learnability of hypothesis classes with respect to arbitrary,
  but bounded loss functions. No characterization of online learnability is known
  at this level of generality. In this paper, we close this gap by showing that existing
  techniques can be used to characterize any online learning problem with a bounded
  loss function. Along the way, we give a new scale-sensitive combinatorial dimension,
  named the Sequential Minimax dimension, that generalizes all existing dimensions
  in online learning theory and provides upper and lower bounds on the minimax value.
openreview: Fc3j44T06e
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: raman25a
month: 0
tex_title: A Unified Theory of Supervised Online Learnability
firstpage: 985
lastpage: 1007
page: 985-1007
order: 985
cycles: false
bibtex_author: Raman, Vinod and Subedi, Unique and Tewari, Ambuj
author:
- given: Vinod
  family: Raman
- given: Unique
  family: Subedi
- given: Ambuj
  family: Tewari
date: 2025-02-17
address:
container-title: Proceedings of The 36th International Conference on Algorithmic Learning
  Theory
volume: '272'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 2
  - 17
pdf: https://raw.githubusercontent.com/mlresearch/v272/main/assets/raman25a/raman25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
