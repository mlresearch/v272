---
title: Non-stochastic Bandits With Evolving Observations
abstract: We introduce a novel online learning framework that unifies and generalizes
  pre-established models, such as delayed and corrupted feedback, to encompass adversarial
  environments where action feedback evolves over time. In this setting, the observed
  loss is arbitrary and may not correlate with the true loss incurred, with each round
  updating previous observations adversarially. We propose regret minimization algorithms
  for both the full-information and bandit settings, with regret bounds quantified
  by the average feedback accuracy relative to the true loss. Our algorithms match
  the known regret bounds across many special cases, while also introducing previously
  unknown bounds.
openreview: MvGTH3S6rN
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bar-on25a
month: 0
tex_title: Non-stochastic Bandits With Evolving Observations
firstpage: 204
lastpage: 227
page: 204-227
order: 204
cycles: false
bibtex_author: Bar-On, Yogev and Mansour, Yishay
author:
- given: Yogev
  family: Bar-On
- given: Yishay
  family: Mansour
date: 2025-02-17
address:
container-title: Proceedings of The 36th International Conference on Algorithmic Learning
  Theory
volume: '272'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 2
  - 17
pdf: https://raw.githubusercontent.com/mlresearch/v272/main/assets/bar-on25a/bar-on25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
